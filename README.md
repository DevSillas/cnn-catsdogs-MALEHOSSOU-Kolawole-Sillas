# CNN from Scratch vs Transfer Learning (Cats vs Dogs)

## Auteur
**Nom :** MALEHOSSOU KolawolÃ© Sillas Shallum
**Master 1 Intelligence Artificielle**

---

## Objectif du projet
Ce projet a pour but de comparer deux approches de Deep Learning appliquÃ©es Ã  la classification dâ€™images du dataset Cats vs Dogs :

1. **ExpÃ©rience A â€” CNN â€œfrom scratchâ€**
   - RÃ©seau convolutionnel construit manuellement avec 3 blocs conv â†’ BatchNorm â†’ Dropout.
   - EntraÃ®nÃ© depuis zÃ©ro sur le dataset.

2. **ExpÃ©rience B â€” Transfert Learning (ResNet18)**
   - RÃ©seau prÃ©-entraÃ®nÃ© sur ImageNet.
   - Couches finales adaptÃ©es pour 2 classes (cat/dog).
   - Objectif : dÃ©montrer la rapiditÃ© de convergence et la robustesse du transfert learning.

Lâ€™enjeu est dâ€™observer lâ€™impact du transfert learning sur la performance, la vitesse de convergence et la gÃ©nÃ©ralisation du modÃ¨le.

---

## Environnement et installation

### Option 1 â€” Utilisation sur **Google Colab**
Le projet est conÃ§u pour fonctionner entiÃ¨rement sur Google Colab (GPU activÃ©).
Aucune installation supplÃ©mentaire nâ€™est nÃ©cessaire.

### Option 2 â€” Utilisation locale
Clonez le projet et installez les dÃ©pendances :

```bash
git clone https://github.com/<ton_nom_utilisateur>/cnn-catsdogs-MALEHOSSOU-Kolawole-Sillas.git
cd cnn-catsdogs-MALEHOSSOU-Kolawole-Sillas
pip install -r requirements.txt

 Environnement Python minimal

Python â‰¥ 3.10

PyTorch â‰¥ 2.0

torchvision â‰¥ 0.15

matplotlib, numpy, pandas, seaborn, scikit-learn
```


## Organisation du projet
 ```bash
cnn-catsdogs-MALEHOSSOU-Kolawole-Sillas/
â”‚
â”œâ”€ notebook.ipynb                â†’ Notebook principal du TP
â”œâ”€ README.md                     â†’ PrÃ©sent fichier
â”œâ”€ requirements.txt              â†’ Librairies nÃ©cessaires
â”œâ”€ .gitignore                    â†’ Fichiers exclus du push
â””â”€ checkpoints/                  â†’ Sauvegarde des modÃ¨les (non poussÃ©s sur GitHub)
```

## Jeu de donnÃ©es

Le dataset Cats vs Dogs provient de Kaggle :
ğŸ”— https://www.kaggle.com/datasets/salader/dogs-vs-cats

Structure attendue :
```bash
Cat_Dog_data/
 â”œâ”€ train/
 â”‚   â”œâ”€ cats/
 â”‚   â””â”€ dogs/
 â””â”€ test/
     â”œâ”€ cats/
     â””â”€ dogs/
```


 Les donnÃ©es ne doivent pas Ãªtre poussÃ©es sur GitHub.
Elles doivent Ãªtre placÃ©es localement dans /content/drive/MyDrive/Exam_deep/Cat_Dog_data/.

## Commandes dâ€™entraÃ®nement
 ```bash
 CNN from scratch
python train.py --model scratch --epochs 10 --batch-size 32 --optimizer adam --dropout 0.5

Transfer Learning (ResNet18)
python train.py --model resnet18 --epochs 8 --batch-size 32 --optimizer adam --lr 1e-4 --freeze True
```

Les modÃ¨les sauvegardÃ©s localement :
checkpoints/best_model_scratch.pth
checkpoints/best_model_transfer.pth

## RÃ©sultats expÃ©rimentaux
ModÃ¨le	Optimiseur	Accuracy	Precision	Recall	F1-score
CNN (from scratch)	Adam	0.53	0.57	0.55	0.56
CNN (SGD + StepLR)	SGD	0.51	0.54	0.52	0.53
ResNet18 (Transfer Learning)	Adam	0.89	0.90	0.88	0.89



## Analyse et interprÃ©tation

Le CNN from scratch converge lentement et plafonne autour de 50â€“55 % dâ€™accuracy.

Le ResNet18 atteint rapidement prÃ¨s de 90 % dâ€™accuracy grÃ¢ce au transfert des poids prÃ©-entraÃ®nÃ©s.

Le transfert learning amÃ©liore nettement la vitesse de convergence et la capacitÃ© de gÃ©nÃ©ralisation.

Lâ€™ajout de BatchNorm et Dropout stabilise lâ€™entraÃ®nement du modÃ¨le â€œfrom scratchâ€.


## Conclusions

Le transfert learning est clairement supÃ©rieur pour un dataset limitÃ©.

Le CNN simple reste essentiel pour la comprÃ©hension des bases du Deep Learning.

ResNet18 + Adam + Scheduler offre le meilleur compromis entre rapiditÃ© et performance.


## AmÃ©liorations possibles

Tester dâ€™autres architectures : MobileNet, EfficientNet, DenseNet.

Ã‰tendre la data augmentation pour rÃ©duire lâ€™overfitting.

Ajouter TensorBoard ou W&B pour le suivi des mÃ©triques.

DÃ©bloquer progressivement certaines couches du modÃ¨le prÃ©-entraÃ®nÃ© (fine-tuning).


## ReproductibilitÃ© et sauvegarde

Tous les modÃ¨les sont sauvegardÃ©s localement (.pth), non poussÃ©s sur GitHub.

Un seed fixe assure la reproductibilitÃ© des rÃ©sultats.

Le notebook vÃ©rifie automatiquement la prÃ©sence du GPU.

Les mÃ©triques (Loss, Accuracy, Precision, Recall) sont tracÃ©es Ã  chaque Ã©poque.


## Fichiers exclus du dÃ©pÃ´t

Le fichier .gitignore contient :
```bash

data/
*.pt
*.pth
__pycache__/
runs/
checkpoints/
.ipynb_checkpoints/
```


MALEHOSSOU KolawolÃ© Sillas Schallum

Ã‰tudiant en Master 1 Intelligence Artificielle

Email : sillfreelance@gmail.com

Projet rÃ©alisÃ© dans le cadre du TP : â€œDeep Learning â€” CNN vs Transfer Learningâ€,

UniversitÃ©: Dakar Institut of Technology, Octobre 2025.


---
